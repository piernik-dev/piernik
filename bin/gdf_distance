#!/usr/bin/env python3
import argparse
import h5py as h5
import numpy as np
import sys
import logging
from typing import Dict, List, Tuple

sp_key = 'simulation_parameters'
pkeys = [['position_x', 'position_y', 'position_z'],
         ['velocity_x', 'velocity_y', 'velocity_z'],
         ['acceleration_x', 'acceleration_y', 'acceleration_z'],
         ['energy'],
         ['mass'],
         ['dynamical_time'],
         ['formation_time']]
pkeys_flat = set()  # to be made from pkeys[]
auto_vectors = True

logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')


def is_comparable(fname1: str, fname2: str) -> bool:
    status = True
    v_key = 'piernik'
    ver = {}
    dim_key = 'dimensionality'
    dim = {}
    geo_key = 'geometry'  # geo_CART = 0, geo_POLAR = 1
    geo = {}

    try:
        h5f1 = h5.File(fname1, "r")
        h5f2 = h5.File(fname2, "r")
    except IOError as e:
        logging.error(f"IOError: {e}")
        return False

    for f in (h5f1, h5f2):
        # piernik versions
        ver[f.filename] = f.attrs[v_key][0]
        if int(ver[f.filename]) != 2:
            logging.error(f"Only Piernik v2 HDF (GDF) files are supported, not {ver[f.filename]}.")
            status = False

        # dimensionality, assume v2 naming conventions
        dim[f.filename] = f[sp_key].attrs[dim_key][0]

        # geometry, assume v2 naming conventions
        geo[f.filename] = f[sp_key].attrs[geo_key][0]

        # Check for some refinement constraints
        levl = set(f["grid_level"])
        if 0 not in levl:
            logging.error(f"Cannot find base level in '{f.filename}'.")
            status = False
        if set(range(max(levl) + 1)) != levl:
            logging.error(f"Missing levels in '{f.filename}'.")
            status = False
        if len(levl) > 1 and f[sp_key].attrs["refine_by"][0] != 2:
            logging.error(f"Only refine factor of 2 is supported. Cannot interpret '{f.filename}'.")
            status = False

    if len(set(map(int, map(float, ver.values())))) > 1:
        logging.error(f"Cannot compare different major file format revisions: {list(ver.values())}")
        status = False

    if len(set(ver.values())) > 1:
        logging.warning("Different revisions of Piernik HDF format. Expect troubles.")

    if len(set(dim.values())) > 1:
        logging.error(f"Cannot compare files with different dimensionality: {list(dim.values())}")
        status = False

    if len(set(geo.values())) > 1:
        logging.error(f"Cannot compare files with different geometries yet: {list(geo.values())}")
        logging.error("It is an interesting idea for future.")
        status = False

    for f in (h5f1, h5f2):
        f.close()

    return status


def compare_domains(h5f1: h5.File, h5f2: h5.File) -> Tuple[float, np.ndarray, np.ndarray]:
    dle_key = 'domain_left_edge'
    dre_key = 'domain_right_edge'
    failed = False

    try:
        dl1, dr1 = h5f1[sp_key].attrs[dle_key], h5f1[sp_key].attrs[dre_key]
        dl2, dr2 = h5f2[sp_key].attrs[dle_key], h5f2[sp_key].attrs[dre_key]
    except KeyError as e:
        logging.error(f"KeyError: {e}")
        exit(10)

    # find overlapped area
    dlo = np.maximum(dl1, dl2)
    dro = np.minimum(dr1, dr2)

    for i in np.subtract(dro, dlo):
        if i < 0.:
            logging.error("Domains don't overlap.")
            return 1., np.zeros(3), np.zeros(3)

    vol_1 = np.prod(np.subtract(dr1, dl1))
    vol_2 = np.prod(np.subtract(dr2, dl2))
    vol_o = np.prod(np.subtract(dro, dlo))
    if vol_1 == 0. and vol_2 == 0.:
        logging.error("Both domains have no volume!")
        exit(11)

    return 1. - vol_o / (vol_1 + vol_2 - vol_o), dlo, dro


def compare_resolution(h5f1: h5.File, h5f2: h5.File) -> float:
    dim_key = "domain_dimensions"

    try:
        res1, res2 = h5f1[sp_key].attrs[dim_key], h5f2[sp_key].attrs[dim_key]
    except KeyError as e:
        logging.error(f"KeyError: {e}")
        exit(30)

    r_norm = 0.
    for i in range(len(res1)):
        r_norm = 1. - (1. - r_norm) * (1. - abs(res1[i] - res2[i]) / float(res1[i] + res2[i]))

    return r_norm


def compare_dlists(h5f1: h5.File, h5f2: h5.File) -> Tuple[float, List[List[str]]]:
    import re

    d_key = '/data'
    g0_key = 'grid_0000000000'  # trick: GDF has to contain this grid id

    f1 = list(h5f1[d_key][g0_key].keys())
    f2 = list(h5f2[d_key][g0_key].keys())

    # Particles should be handled separately
    for f in (f1, f2):
        if "particles" in f:
            f.remove("particles")

    fc = list(set(f1) & set(f2))
    if ("cree01" in f1) == ("cr_e-e01" in f2):
        f1c = []
        f2c = []
        cre_ = re.compile("^cre[en][0-9][0-9]").search
        for f in f1:
            f1c.append(f.replace("cre", "cr_e-") if bool(cre_(f)) else f)
        for f in f2:
            f2c.append(f.replace("cre", "cr_e-") if bool(cre_(f)) else f)
        fc = list(set(f1c) & set(f2c))
        logging.info("Comparing CR components with old and new names (like 'cree01' translated to 'cr_e-e01')")
    if len(fc) != len(f1):
        logging.info(f"Fields unique for `{h5f1.filename}`: {list(set(f1) ^ set(fc))}")
    if len(fc) != len(f2):
        logging.info(f"Fields unique for `{h5f2.filename}`: {list(set(f2) ^ set(fc))}")

    v0 = []
    for f in fc:
        if f[-1] == 'x' or f[-2] == 'x' or f[-2:] == '01':
            v0.append(f)

    vec = []
    for v in v0:
        vv = []
        if v[-1] == 'x':
            vv = [v]
            for f in fc:
                for i in ('y', 'z'):
                    if f == v[:-1] + i:
                        vv.append(f)
        elif v[-2] == 'x':
            vv = [v]
            for f in fc:
                for i in ('y', 'z'):
                    if f == v[:-2] + i + v[-1]:
                        vv.append(f)
        elif v[-2:] == '01':
            digit2 = re.compile(v[:-2].replace("+", "\\+") + "[0-9][0-9]").search
            for f in fc:
                if bool(digit2(f)):
                    vv.append(f)
        else:
            logging.error(f"Unsupported case {v}")
            exit(40)

        if len(vv) > 1:
            vec.append(vv)

    b = []
    for v in vec:
        b += v
    if len(vec) > 0:
        logging.info("Possible vectors:")
        for v in vec:
            logging.info(f"    {sorted(v)}")
        logging.info(f"Remaining fields:")
        logging.info(f"    {list(set(fc) ^ set(b))}")

    if auto_vectors:
        for v in list(set(fc) ^ set(b)):
            vec.append([v])
    else:
        vec = []
        for v in fc:
            vec.append([v])

    return 0. if len(f1) == len(fc) and len(f2) == len(fc) else 1. - len(fc) / float(len(f1) + len(f2) - len(fc)), vec  # correct also for empty sets


def compare_time(h5f1: h5.File, h5f2: h5.File) -> float:
    time_key = "time"
    t1 = h5f1.attrs[time_key][0]
    t2 = h5f2.attrs[time_key][0]
    if t1 > 0. and t2 > 0.:
        return abs(t1 - t2) / (t1 + t2)
    else:
        if t1 == 0.:
            return 0.
        else:
            return 1.


def compare_data(ds1: np.ndarray, ds2: np.ndarray) -> float:
    # This norm is:
    #   0. when n1 == n2
    #   1. when one field is non-0. and the other is 0.
    #   1. when one field is proportional to the other but with negative coefficient
    #   epsilon/2 when difference between fields is epsilon

    # When np.shape(ds1)[0] > 1 (the data is vector, not scalar), the formula doesn't change because we use the default, Frobenius norm.

    n1 = np.linalg.norm(ds1)
    n2 = np.linalg.norm(ds2)
    nd = np.linalg.norm(ds1 - ds2)

    if n1 + n2 != 0.:
        return nd / (n1 + n2)
    else:
        return 0.


def collect_dataset(h5f: h5.File, dset_name: List[str], level: int) -> Tuple[np.ndarray, List[int], bool]:
    attrs = h5f['domains']['base'].attrs
    nd = [i * 2**level for i in attrs['n_d']]
    dset = np.zeros((len(dset_name), nd[0], nd[1], nd[2]))

    levelmet = False
    for ig in range(int(h5f['data'].attrs['cg_count'][0])):
        h5g = h5f['data']['grid_' + str(ig).zfill(10)]
        if h5g.attrs['level'] == level:
            levelmet = True
            off = h5g.attrs['off']
            ngb = h5g.attrs['n_b']
            n_b = [int(ngb[0]), int(ngb[1]), int(ngb[2])]
            ce = n_b + off
            for i in range(len(dset_name)):
                if dset_name[i] in h5g:
                    ds = dset_name[i]
                elif dset_name[i].replace("cr_e-", "cre") in h5g:
                    ds = dset_name[i].replace("cr_e-", "cre")
                else:
                    raise KeyError
                dset[i, off[0]:ce[0], off[1]:ce[1], off[2]:ce[2]] = h5g[ds][:, :, :].swapaxes(0, 2)

    return dset, nd, levelmet


def get_particles(h5f: h5.File) -> Dict[str, np.ndarray]:
    plist = {}
    if "grid_particle_count" not in h5f:
        return plist
    n = sum(h5f['grid_particle_count'])
    nf = 0
    for ig in range(h5f['grid_dimensions'].shape[0]):
        h5g = h5f['data']['grid_' + str(ig).zfill(10)]
        if "particles" in h5g:
            if "stars" in h5g["particles"]:
                h5gps = h5g["particles"]["stars"]
                nf += h5gps.attrs['n_part'][0]
                for v in h5gps.keys():
                    if v not in plist:
                        plist[v] = []
                    plist[v] = np.append(plist[v], h5gps[v])
    if nf != n:
        logging.warning(f"Read {nf} particles from '{h5f.filename}', {n} expected.")
    else:
        logging.info(f"Read {nf} particles from '{h5f.filename}'.")

    for v in plist:
        if len(plist[v]) != n:
            logging.warning(f"Incomplete list for particle quantity '{v}' in '{h5f.filename}': read {len(plist[v])} out of {n}.")
    for i in pkeys:
        for j in i:
            pkeys_flat.add(j)
    if not auto_vectors:
        pkeys.clear()
        for i in pkeys_flat:
            pkeys.append([i])
    if "id" in plist.keys():
        if set(plist.keys()) != (set(pkeys_flat) ^ set(['id'])):
            logging.warning(f"Non-standard set of particle quantities detected in '{h5f.filename}': {set(plist.keys())}")
    return plist


def convert_particles(p: Dict[str, np.ndarray]) -> Dict[int, Dict[str, float]]:
    pp = {}
    dupl = []
    maxdupl = 8
    ndupl = 0
    for i in range(len(p["id"])):
        particle_id = int(p["id"][i])
        if particle_id in pp:
            if len(dupl) < maxdupl:
                dupl.append(particle_id)
            ndupl += 1
        pp[particle_id] = {}
        for k in pkeys_flat:
            pp[particle_id][k] = p[k][i]
    if ndupl > 0:
        logging.warning(f"{ndupl} duplicated id found [ {str(dupl)[1:-1]} {('...' if ndupl > maxdupl else '')} ]")
    return pp


# I'm afraid this might be quite slow on large particle sets
def compare_particles(h5f1: h5.File, h5f2: h5.File) -> Dict[str, float]:
    pn = {}
    p1 = get_particles(h5f1)
    p2 = get_particles(h5f2)
    if "id" not in p1 and "id" not in p2:
        return pn
    if len(p1["id"]) == 0 and len(p2["id"]) == 0:
        return pn
    try:
        if len(p1["id"]) != len(p2["id"]):
            pn["particles count"] = abs(len(p1["id"]) - len(p2["id"])) / (len(p1["id"]) + len(p2["id"]))
    except KeyError:  # only one contains "id"
        pn["particles exists"] = 1
        return pn

    pp1 = convert_particles(p1)
    pp2 = convert_particles(p2)

    n_comm_p = len(set(pp1.keys()) & set(pp2.keys()))
    pn["particles id"] = 1. - 2 * n_comm_p / (len(pp1.keys()) + len(pp2.keys()))

    for particle_id in pp1.copy().keys():
        if particle_id not in pp2:
            del pp1[particle_id]

    tot_datanorm = 0.
    for kv in pkeys:
        ds1 = np.zeros((n_comm_p * len(kv)))
        ds2 = np.zeros((n_comm_p * len(kv)))
        i = 0
        for particle_id in pp1:  # we've already removed particles that were unique to pp1
            for k in kv:
                ds1[i] = pp1[particle_id][k]
                ds2[i] = pp2[particle_id][k]
                i += 1
        norm = compare_data(ds1, ds2)
        # Assumed that the only vectors for particles are the XYZ-vectors
        pn[f"particles `{kv[0] if len(kv) == 1 else kv[0][:-2] + '_[x..z]'}`"] = norm
        tot_datanorm = 1. - (1. - tot_datanorm) * (1. - norm)
    logging.info(f"All particles difference: {tot_datanorm}")

    return pn


def base_compare(h5f1: h5.File, h5f2: h5.File) -> Tuple[Dict[str, float], List[List[str]]]:
    norms = {}
    # compare time
    norms["time"] = compare_time(h5f1, h5f2)

    # compare domains
    norms["domains"], dlo, dro = compare_domains(h5f1, h5f2)

    # compare resolution
    norms["resolution"] = compare_resolution(h5f1, h5f2)

    # compare boundary types
    norms["boundary types (not checked)"] = 0.

    # compare datafield lists
    norms["datafield lists"], common_fields = compare_dlists(h5f1, h5f2)

    # compare particles
    norms.update(compare_particles(h5f1, h5f2))

    if norms["domains"] < 1.:
        # compare AMR coverage (norm of difference of resolution on overlapped part of the domain)
        norms["AMR (not checked)"] = 0.

    if not (norms["domains"] == 0 and norms["resolution"] == 0):
        logging.error("Comparing domains of different size or resolution is not implemented yet")
        exit(31)

    return norms, common_fields


def compare_datafields_by_level(h5f1: h5.File, h5f2: h5.File, levels: Tuple[int, int], common_fields: List[List[str]],
                                fname1: str, fname2: str, print_fname: bool) -> Dict[str, float]:
    lnorm = {}
    # No error checking here, fail in ugly way when is_comparable does not
    # prevent attempt to open these files.

    tot_datanorm = 0.
    for f in common_fields:
        ds1, nd1, levok1 = collect_dataset(h5f1, f, levels[0])
        ds2, nd2, levok2 = collect_dataset(h5f2, f, levels[1])
        if not levok1:
            print('Level %s not met in %s.' % (levels[0], fname1))
            exit(51)
        if not levok2:
            print('Level %s not met in %s.' % (levels[1], fname2))
            exit(52)
        if nd1[0] != nd2[0] or nd1[1] != nd2[1] or nd1[2] != nd2[2]:
            print('Domain shape for %s level %s: %s' % (fname1, levels[0], nd1))
            print('Domain shape for %s level %s: %s' % (fname2, levels[1], nd2))
            print('Arrays cannot be compered.')
            exit(53)
        norm = compare_data(ds1, ds2)
        if len(f) == 1:
            fld_name = f[0]
        else:
            if sorted(f)[0][-1] == 'x':
                fld_name = sorted(f)[0][:-1] + '[x..' + sorted(f)[-1][-1] + ']'
            elif sorted(f)[0][-2] == 'x':
                fld_name = sorted(f)[0][:-2] + '[x..' + sorted(f)[-1][-2] + ']' + sorted(f)[0][-1]
            elif sorted(f)[0][-2:] == '01':
                fld_name = sorted(f)[0][:-2] + '[01..' + sorted(f)[-1][-2:] + ']'
            else:
                fld_name = '[' + sorted(f)[0] + ".." + sorted(f)[-1] + ']'
        lnorm["datafield `" + fld_name + "'"] = norm
        tot_datanorm = 1. - (1. - tot_datanorm) * (1. - norm)
    if levels[0] == levels[1]:
        lev = str(levels[0])
    else:
        lev = str(levels[0]) + ' vs. ' + str(levels[1])
    print("All datafield difference%s on grid level %s: %g" % (
        (" between '%s' and '%s'" % (fname1, fname2)) if print_fname else "",
        lev, tot_datanorm))

    return lnorm


def piernik_gdf_compare(fname1, fname2, levels, print_fname=False):
    h5f1 = h5.File(fname1, "r")
    h5f2 = h5.File(fname2, "r")

    normsl = []
    norms, common_fields = base_compare(h5f1, h5f2)
    if levels == []:
        maxlev1 = max(h5f1['grid_level'])
        maxlev2 = max(h5f2['grid_level'])
        nlev = range(min(maxlev1, maxlev2) + 1)
        for lev in nlev:
            normsl.append(compare_datafields_by_level(h5f1, h5f2, (lev, lev), common_fields, fname1, fname2, print_fname))
    else:
        normsl.append(compare_datafields_by_level(h5f1, h5f2, levels, common_fields, fname1, fname2, print_fname))
        nlev = range(1)

    h5f1.close()
    h5f2.close()
    return norms, normsl, nlev


def n_reduce(args):
    norms, normsl, nlev = args
    n = {}
    for i in sorted(norms.keys()):
        n[i] = norms[i]
    for i in sorted(normsl[0].keys()):
        for lev in nlev:
            if i in n:
                n[i] += (1. - n[i]) * normsl[lev][i]
            else:
                n[i] = normsl[lev][i]

    return n


if __name__ == "__main__":
    import sys

    # Ugly. ToDo: rewrite and use argparse.
    novec = "--novec"
    if novec in sys.argv:
        sys.argv.remove(novec)
        auto_vectors = False
        sys.stderr.write("Switched to nondetection of vectors\n")
    if (len(sys.argv) < 3):
        sys.stderr.write("Error: too few arguments.\nUsage: " +
                         sys.argv[0] + " piernik_data_hdf_file1 piernik_data_hdf_file2 [piernik_data_hdf_file3]\n" + "or     " +
                         sys.argv[0] + " piernik_data_hdf_file1 piernik_data_hdf_file2 level1 level2\n")
        exit(1)

    if (len(sys.argv) == 3) or (len(sys.argv) == 5):
        if (is_comparable(sys.argv[1], sys.argv[2])):
            if (len(sys.argv) == 5):
                levels = [int(sys.argv[3]), int(sys.argv[4])]
            else:
                levels = []
            norms, normsl, nlev = piernik_gdf_compare(sys.argv[1], sys.argv[2], levels)
            tot_norm = 0.
            failed = False
            longestkey = max(len(max(norms, key=len)), len(max(normsl[0], key=len))) if len(norms) != 0 else 0
            for i in sorted(norms.keys()):
                toprint = "Difference of %-*s:" % (longestkey + 1, i)
                if (norms[i] >= 0. and norms[i] <= 1. + 1e-12):
                    toprint = toprint + "   %14g" % norms[i]
                    # tot_norm = 1. - (1. - tot_norm) * (1. - norms[i])
                    tot_norm += (1. - tot_norm) * norms[i]
                else:
                    print("Difference measure `%s` out of [0,1] range: %g" %
                          (i, norms[i]))
                    failed = True
                if not failed:
                    print(toprint)
            for i in sorted(normsl[0].keys()):
                toprint = "Difference of %-*s:" % (longestkey + 1, i)
                for lev in nlev:
                    if (normsl[lev][i] >= 0. and normsl[lev][i] <= 1. + 1e-12):
                        toprint = toprint + "   %14g" % normsl[lev][i]
                        # tot_norm = 1. - (1. - tot_norm) * (1. - norms[i])
                        tot_norm += (1. - tot_norm) * normsl[lev][i]
                    else:
                        print("Difference measure `%s` out of [0,1] range: %g" %
                              (i, normsl[lev][i]))
                        failed = True
                if not failed:
                    print(toprint)
            if (failed):
                print("Comparison of `%s' and `%s' failed" %
                      (sys.argv[1], sys.argv[2]))
                exit(3)
            else:
                print("Total difference between `%s' and `%s': %g" %
                      (sys.argv[1], sys.argv[2], tot_norm))
        else:
            print("Cannot compare files `%s' and `%s'" %
                  (sys.argv[1], sys.argv[2]))
            exit(2)
    elif (len(sys.argv) == 4) or (len(sys.argv) == 7):
        if (is_comparable(sys.argv[1], sys.argv[2]) and is_comparable(sys.argv[1], sys.argv[3])):
            if (len(sys.argv) == 7):
                l12 = [int(sys.argv[4]), int(sys.argv[5])]
                l13 = [int(sys.argv[4]), int(sys.argv[6])]
                l23 = [int(sys.argv[5]), int(sys.argv[6])]
            else:
                l12, l13, l23 = [], [], []
            n12 = n_reduce(piernik_gdf_compare(sys.argv[1], sys.argv[2], l12, print_fname=True))
            print("")
            n13 = n_reduce(piernik_gdf_compare(sys.argv[1], sys.argv[3], l13, print_fname=True))
            print("")
            n23 = n_reduce(piernik_gdf_compare(sys.argv[2], sys.argv[3], l23, print_fname=True))
            print("")
            norms = dict(n12)
            norms.update(n13)
            norms.update(n23)
            longestkey = len(max(norms, key=len))
            print("Files:")
            for i in (1, 2, 3):
                print("  %d - %s" % (i, sys.argv[i]))
            print("\n%-*s: %-14s %-14s %-14s" % (longestkey + len("Difference of ") + 1, "distance type (all levels)", " 1-2", " 1-3", " 2-3"))
            c_red = '\033[91m'
            c_green = '\033[92m'
            c_reset = '\033[0m'
            c_gray = '\033[90m'
            for i in norms.keys():
                line = "Difference of %-*s: " % (longestkey + 1, i)
                comment = ""
                curnorm = []
                for nn in (n12, n13, n23):
                    if (i in nn):
                        curnorm.append(nn[i])
                lmin = min(curnorm)
                lmax = max(curnorm)
                for nn in (n12, n13, n23):
                    try:
                        color = ""
                        if (lmax > lmin):
                            if (nn[i] == lmax):
                                color = c_red
                            elif (nn[i] == lmin):
                                color = c_green
                        line += (" %s%-14g" % (color, nn[i])) + c_reset
                        if (nn[i] < 0. or nn[i] > 1.):
                            comment += " Value %g out of [0,1] range!" % nn[i]
                    except (KeyError):
                        line += c_gray + (" %14s" % "N/A") + c_reset
                print(line + comment)
        else:
            print("Cannot compare files `%s', `%s' and `%s'" %
                  (sys.argv[1], sys.argv[2], sys.argv[3]))
            exit(3)
    else:
        print("Too many arguments:", sys.argv)
        exit(4)
